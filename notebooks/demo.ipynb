{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00dc0a2b-ea74-4734-95cc-fda4e25e8e5d",
   "metadata": {},
   "source": [
    "# LoS Detection Strategy \n",
    "\n",
    "To detect the level of service (LOS) of a highway from a video of traffic, you would typically follow a series of steps involving video processing, vehicle detection and tracking, and LOS classification. Here's an outline of the process:\n",
    "\n",
    "1. Video Preprocessing\n",
    "Frame Extraction: Extract frames from the video at regular intervals, say every 5 seconds.\n",
    "Stabilization (if necessary): If the video is shaky or moving, apply video stabilization techniques to make it more suitable for analysis.\n",
    "2. Vehicle Detection and Tracking\n",
    "Object Detection: Use a deep learning model like YOLO (You Only Look Once), SSD (Single Shot Multibox Detector), or Faster R-CNN to detect vehicles in each frame.\n",
    "Object Tracking: Implement a tracking algorithm such as SORT (Simple Online and Realtime Tracking) or DeepSORT to track the detected vehicles over multiple frames.\n",
    "3. Traffic Flow Analysis\n",
    "Vehicle Count: Count the number of vehicles passing through a defined section of the highway in each 5-second interval.\n",
    "Speed Estimation: Estimate the speed of each tracked vehicle by measuring the distance covered between frames and knowing the frame rate and camera calibration.\n",
    "Density Estimation: Calculate the density of vehicles on the highway segment by counting the number of vehicles per unit length of the road.\n",
    "4. Level of Service (LOS) Classification\n",
    "Traffic Flow Parameters: The LOS is determined based on parameters like speed, density, and flow (vehicles per hour). Use these metrics to classify the LOS.\n",
    "- Free Flow (LOS A): Low vehicle density, high speed, and smooth traffic flow.\n",
    "- Stable Flow (LOS B, C, D): Increasing vehicle density with minor to moderate delays.\n",
    "- Unstable Flow (LOS E): High vehicle density with frequent stops and low speeds.\n",
    "- Forced or Breakdown Flow (LOS F): Traffic congestion with very low speeds and frequent stops.\n",
    "- Classification Model: You can use predefined thresholds for these parameters or train a machine learning model to classify the LOS based on historical data.\n",
    "5. Output Generation\n",
    "Time-Series Data: Generate a time series of LOS values every 5 seconds based on the analysis.\n",
    "Visualization: Create visualizations or reports showing how the LOS changes over time during the video.\n",
    "Tools and Libraries\n",
    "OpenCV: For video processing and vehicle detection/tracking.\n",
    "TensorFlow/PyTorch: For implementing deep learning models for object detection.\n",
    "Scikit-learn/Pandas: For data analysis and LOS classification.\n",
    "Custom Scripts: For calculating traffic flow parameters and LOS.\n",
    "Example Workflow:\n",
    "Extract Frames: Extract frames at 5-second intervals from the video.\n",
    "Detect and Track Vehicles: Detect vehicles in each frame and track their movement across frames.\n",
    "Calculate Traffic Metrics: Compute the speed, count, and density of vehicles.\n",
    "Classify LOS: Use the calculated metrics to determine the LOS for each 5-second interval.\n",
    "Generate Output: Produce a report or visual representation of LOS over time.\n",
    "This approach provides a continuous and dynamic assessment of the highway's level of service using video data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4d0f74-1d22-41db-a043-4c89a63db4aa",
   "metadata": {},
   "source": [
    "# 1. Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a45e8d-e828-45a5-b4e2-53c81407ed95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fcc024-a997-4bb4-8ea3-ccd0f03bfc63",
   "metadata": {},
   "source": [
    "# Setup constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5067dc5-a6a0-4a62-beca-0e67097e3bce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "mqt_broker = 'mqtt-broker.trafficcounter.svc.cluster.local'\n",
    "streaming_server = 'http://cv-streamer-trafficcounter.apps.ocpbare.davenet.local/stream/gdot-cameraC01.m3u8'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d064f23d-6c2d-4cd6-b40f-c6c2fb5e243e",
   "metadata": {},
   "source": [
    "# 3. Run the analysis on the stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1ccffd-9c83-4f6a-93f3-d3da70e4d0f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import paho.mqtt.client as mqtt\n",
    "import json\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "# Initialize MQTT client\n",
    "mqtt_client = mqtt.Client()\n",
    "mqtt_client.connect(mqt_broker, 1883, 60)  # Use your service name and port\n",
    "\n",
    "# Constants\n",
    "FRAME_INTERVAL = 5  # seconds\n",
    "VIDEO_FPS = 15  # Estimated FPS for the stream; adjust as necessary\n",
    "FRAME_SKIP = FRAME_INTERVAL * VIDEO_FPS\n",
    "\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture(streaming_server)\n",
    "frame_count = 0\n",
    "\n",
    "def calculate_speed(centroid_prev, centroid_current, fps):\n",
    "    distance = np.linalg.norm(np.array(centroid_current) - np.array(centroid_prev))\n",
    "    speed = distance * fps  # Simplified speed calculation\n",
    "    return speed\n",
    "\n",
    "def calculate_LOS(vehicle_count, vehicle_speeds):\n",
    "    avg_speed = np.mean(vehicle_speeds) if vehicle_speeds else 0\n",
    "    density = vehicle_count / 100  # Simplified assumption of road length\n",
    "    \n",
    "    if density < 10 and avg_speed > 60:\n",
    "        return 'A'\n",
    "    elif density < 20 and avg_speed > 50:\n",
    "        return 'B'\n",
    "    elif density < 30 and avg_speed > 40:\n",
    "        return 'C'\n",
    "    elif density < 40 and avg_speed > 30:\n",
    "        return 'D'\n",
    "    elif density < 50 and avg_speed > 20:\n",
    "        return 'E'\n",
    "    else:\n",
    "        return 'F'\n",
    "\n",
    "# Tracking state\n",
    "tracked_vehicles = {}\n",
    "los_over_time = []\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    frame_count += 1\n",
    "    if frame_count % FRAME_SKIP != 0:\n",
    "        continue\n",
    "    \n",
    "    # Inference\n",
    "    results = model(frame, verbose=False)\n",
    "    \n",
    "    vehicle_count = 0\n",
    "    vehicle_speeds = []\n",
    "    \n",
    "    for result in results[0].boxes:\n",
    "        x1, y1, x2, y2 = result.xyxy[0].cpu().numpy()  # Move tensor to CPU before converting to NumPy\n",
    "        cls = int(result.cls[0].cpu().numpy())  # Move tensor to CPU before converting to NumPy\n",
    "        \n",
    "        if cls in [2, 3, 5, 7]:  # Consider only cars, buses, trucks\n",
    "            vehicle_count += 1\n",
    "            centroid = ((x1 + x2) / 2, (y1 + y2) / 2)\n",
    "            \n",
    "            # Speed calculation (Simplified)\n",
    "            if vehicle_count in tracked_vehicles:\n",
    "                speed = calculate_speed(tracked_vehicles[vehicle_count], centroid, VIDEO_FPS)\n",
    "                vehicle_speeds.append(speed)\n",
    "            \n",
    "            tracked_vehicles[vehicle_count] = centroid\n",
    "            \n",
    "            # Draw bounding box and label\n",
    "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f'Vehicle', (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "    \n",
    "    los = calculate_LOS(vehicle_count, vehicle_speeds)\n",
    "    los_over_time.append(los)\n",
    "    \n",
    "    # Add LOS label to the frame\n",
    "    cv2.putText(frame, f'LOS: {los}', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3)\n",
    "    \n",
    "    # Convert BGR (OpenCV format) to RGB (Matplotlib format)\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Encode the frame to JPEG\n",
    "    _, buffer = cv2.imencode('.jpg', frame)\n",
    "    jpg_as_text = buffer.tobytes().decode('latin1')  # Convert to string to send over MQTT\n",
    "\n",
    "    # Prepare data to publish to MQTT\n",
    "    data = {\n",
    "        'frame': frame_count,\n",
    "        'second': frame_count // VIDEO_FPS,\n",
    "        'los': los,\n",
    "        'image': jpg_as_text  # Include the image as a string\n",
    "    }\n",
    "    \n",
    "    # Publish to MQTT topic\n",
    "    mqtt_client.publish('traffic/los', json.dumps(data))\n",
    "    \n",
    "    # Display the frame (optional)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(frame_rgb)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # Wait for the actual time interval (5 seconds)\n",
    "    time.sleep(FRAME_INTERVAL)\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# Output LOS over time\n",
    "for time, los in enumerate(los_over_time):\n",
    "    print(f\"Time {time * FRAME_INTERVAL}s: LOS {los}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e0f6f1-ab48-4bd3-bd48-1755247eeaea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2908a1c4-8871-4bbb-b3c3-72f95abdee59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
